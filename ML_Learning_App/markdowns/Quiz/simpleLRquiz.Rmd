---
title: "Simple Linear Regression"
output: 
  learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(r02pro)
library(tidyverse)
```

We will be predicting the housing price using the `sahp` dataset in the **r02pro** package. Please answer the following questions.

You can run the following code to prepare the analysis.
```{r}
my_sahp <- sahp %>% 
  na.omit() %>%
  select(gar_car, liv_area, kit_qual, sale_price)
my_sahp_train <- my_sahp[1:100, ]
my_sahp_test <- my_sahp[-(1:100), ]

head(my_sahp)
```

Using the training data `my_sahp_train` to fit a simple linear regression model of `sale_price` on each variable (`gar_car`, `liv_area`, `kit_qual`) separately. For each regression,

    a. Interpret the coefficients and compute the $R^2$. Which variable is most useful in predicting the `sale_price`?
    b. Comput the fitted value and the prediction on the test data, then compute the training and test error. Which variable gives the smallest test error? Does this agree with the variable with the highest $R^2$? Explain your findings.

```{r simpleLRQ1, exercise = TRUE}

```

```{r simpleLRQ1-solution}
vars <- c("gar_car", "liv_area", "kit_qual")
R2_seq <- NULL
train_error_seq <- NULL
test_error_seq <- NULL
re <- NULL
beta_coef_seq <- NULL
for(var_ind in seq_along(vars)){
  var <- vars[var_ind]
  fit <- lm(sale_price ~., data = my_sahp_train %>% select(sale_price, all_of(var)))
  print(coef(fit))
  sale_price_pred <- predict(fit, newdata = my_sahp_train)
  train_error_seq[var_ind] <- sum((my_sahp_train$sale_price - sale_price_pred)^2)
  sale_price_pred <- predict(fit, newdata = my_sahp_test)
  test_error_seq[var_ind] <- sum((my_sahp_test$sale_price - sale_price_pred)^2)
  R2_seq[var_ind] <- summary(fit)$r.squared
 
}
 lm_re <- data.frame(var = vars,
                  R2 = R2_seq,
                  train_error = train_error_seq,
                  test_error = test_error_seq)
 lm_re
```

