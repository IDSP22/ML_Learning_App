---
title: "K Nearest Neighbors"
output: html_document
runtime: shiny
---


### KNN: Different choice of $K$



```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(MASS)     #INSTALL IF NEEDED
library(caret) 
mytheme <- theme(axis.title = element_text(size = 30),
        axis.text = element_text(size = 20))
x <- seq(from = -6, to = 6, by = 0.1)
n <- length(x)
y_true <- sin(x)    #true function
y <- y_true + rnorm(length(x))
train_dat <- data.frame(x = x, y = y, y_true = y_true)
```




```{r eruptions, echo=FALSE}

inputPanel(

  
  sliderInput("k", label = "Number of k:",
              min = 1, max = 121, value = 1, step = 10)
)

renderPlot({
  
  
x_test <- seq(from = -6, to = 6, by = 0.01)  #test data
y_true_test <- sin(x_test)
y_test <- y_true_test + rnorm(length(x_test))
pred_dat <- NULL
test_error_seq <- train_error_seq <- rep(0, 3)
fit <- knnreg(data.frame(x), y, k = input$k)
y_test_hat <- predict(fit, data.frame(x_test))
test_error <- sum((y_test - y_test_hat)^2)
y_train_hat <- predict(fit, data.frame(x))
train_error <- sum((y - y_train_hat)^2)
pred_dat <- rbind(pred_dat,
                    data.frame(x = x_test,
                               y = y_test_hat,
                               y_true = y_test,
                               k = input$k))
  text <- paste(c("K =", input$k, "Train Error:", train_error, "Test Error", test_error), collapse = " ") 
  
  ggplot(pred_dat) + 
  geom_point(mapping = aes(x = x,
                           y = y),
             data = train_dat,
             alpha = 0.5,
             color = "black") +
    
  geom_point(mapping = aes(x = x, 
                           y = y,
                           color = factor(input$k)))+
  geom_line(mapping = aes(x = x,
                          y = y_true),
            data = train_dat,
            size = 2) + annotate ("text", x = 0, y = -2.5,
                                           label = text,
                                          size = 5,
                                        )
    

  
  
})
```


####   Interpretation
- $K=1$: perfect fit on training data, too rough, bias low, [variance high]{color="red"}
- $K=121$ (sample size): constant fit, just the sample average, too smooth, [bias high]{color="red"}, variance low (0)
- $K=10$: a good balance
